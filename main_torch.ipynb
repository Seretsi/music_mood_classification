{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Neural Model",
   "id": "253c8b9d77588ae4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T15:21:54.442508Z",
     "start_time": "2025-12-03T15:21:53.079049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "import torch.cuda\n",
    "import numpy as np\n",
    "\n",
    "# inspect torch path file\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "checkpoint = torch.load(\"deam_processed/best_model.pth\", map_location=device)\n",
    "print(checkpoint.keys())\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ],
   "id": "33fcbd27bf7b57fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'output.weight', 'output.bias'])\n",
      "CUDA available: False\n",
      "CUDA version: None\n",
      "GPU count: 0\n",
      "Using cpu device\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load data",
   "id": "58b908136d676c11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T16:27:52.671657Z",
     "start_time": "2025-12-03T16:27:52.608042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# grab MERGE data\n",
    "# VGGish\n",
    "verbose = False\n",
    "nn_features = np.load(\"data/Audio Features and Model/extracted_features/extracted_features/vggish_features_meanpool.npz\")\n",
    "if True:\n",
    "    print('nn_features')\n",
    "    print(nn_features.files)\n",
    "    print(nn_features[\"filenames\"])\n",
    "    print(nn_features[\"features\"].shape)\n",
    "\n",
    "#X_audio\n",
    "ids_train = np.load(\"data/Audio Features and Model/extracted_features/extracted_features/splits/ids_train.npy\")\n",
    "if verbose:\n",
    "    print('ids_train')\n",
    "    print(ids_train.shape)\n",
    "    print(ids_train)\n",
    "\n",
    "ids_val = np.load(\"data/Audio Features and Model/extracted_features/extracted_features/splits/ids_val.npy\")\n",
    "if verbose:\n",
    "    print('ids_val')\n",
    "    print(ids_val.shape)\n",
    "    print(ids_val)\n",
    "\n",
    "ids_test = np.load(\"data/Audio Features and Model/extracted_features/extracted_features/splits/ids_test.npy\")\n",
    "if verbose:\n",
    "    print('ids_test')\n",
    "    print(ids_test.shape)\n",
    "    print(ids_test)\n",
    "\n",
    "# RoBERTa\n",
    "# X_lyrics\n",
    "panda_merge_lyrics_features = pd.read_csv(\"data/Lyrics Features and Model/lyrics_embeddings_FULL/embeddings_128dim_with_metadata.csv\")\n",
    "if False:\n",
    "    print(panda_merge_lyrics_features.columns)\n",
    "    print(panda_merge_lyrics_features.head())\n",
    "\n",
    "test_lyrics_features = np.load(\"data/Lyrics Features and Model/lyrics_embeddings_FULL/test_embeddings_128dim.npy\")\n",
    "if True:\n",
    "    print('test_lyrics_features')\n",
    "    print(test_lyrics_features.shape)\n",
    "    # print(test_lyrics_features)\n",
    "\n",
    "# Y\n",
    "Y_pred = pd.read_csv(\"data/MERGE_Bimodal_Complete/merge_bimodal_complete_av_values.csv\")\n",
    "if verbose:\n",
    "    print(Y_pred.columns)\n",
    "    print(Y_pred.head())\n"
   ],
   "id": "6930f7cc86754b04",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_features\n",
      "['features', 'labels', 'filenames']\n",
      "['A001' 'A002' 'A003' ... 'MT0036368550' 'MT0039250520' 'MT0041030749']\n",
      "(2216, 128)\n",
      "test_lyrics_features\n",
      "(384, 128)\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Preprocessing",
   "id": "4bf7fef52e61c2da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T17:41:58.573276Z",
     "start_time": "2025-12-03T17:41:58.019132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_features(audio_ids, audio_features_file, lyrics_features, truth_pred):\n",
    "    \"\"\"\n",
    "    Extract V/A features from three data sets representing the audio, lyrics and true predictions of VA values.\n",
    "    :param audio_ids: file of ids to identity songs in split\n",
    "    :param audio_features: audio features\n",
    "    :param lyrics_features: lyrics features\n",
    "    :param truth_pred: A/V true features\n",
    "    :return: np.arrays X, Y, shape N,4 and N,2 respectively\n",
    "    \"\"\"\n",
    "    X = np.empty((1, 128))\n",
    "    Y = np.empty((1, 2))\n",
    "    count = 0\n",
    "    audio_feature_name = np.array(audio_features_file['filenames'])\n",
    "    audio_features = np.array(audio_features_file['features'])\n",
    "    print(audio_features[0].shape)\n",
    "    # print(audio_ids)\n",
    "    missing_count = 0\n",
    "    for i in range(audio_ids.shape[0]):\n",
    "        song_id = audio_ids[i] # get song id in training splits\n",
    "        Y_row = truth_pred[truth_pred[\"Audio_Song\"] == song_id]\n",
    "        lyrics_id = Y_row[\"Lyric_Song\"]\n",
    "        if len(lyrics_id) == 0:\n",
    "            print(\"song_id: \", song_id, \", missing in lyrics_id\")\n",
    "            continue\n",
    "        if False:\n",
    "            print(lyrics_id)\n",
    "        feature_loc = np.where(audio_feature_name == song_id)[0]\n",
    "        lyrics_id = lyrics_id.item()\n",
    "        lyrics_features_row = lyrics_features[lyrics_features['song_id'] == lyrics_id]\n",
    "        # print(lyrics_features_row.values)\n",
    "        if (lyrics_features_row.shape[0] == 0):\n",
    "            missing_count += 1\n",
    "            if verbose:\n",
    "                print(\"song_id: \", song_id, \", missing lyrics features\")\n",
    "            continue\n",
    "        lyrics_feature = lyrics_features_row.values[0][1:129]\n",
    "        audio_feature = np.array(audio_features[feature_loc]).flatten()\n",
    "        y_bimodal = np.flip(Y_row.values[0][2:4])\n",
    "        # print(np.sum(lyrics_feature))\n",
    "        xEntry = np.concatenate([lyrics_feature])\n",
    "        X = np.vstack([X, xEntry])\n",
    "        Y = np.vstack([Y, y_bimodal])\n",
    "        count+=1\n",
    "    print('run stats')\n",
    "    print('count: ', count)\n",
    "    print('missing: ', missing_count)\n",
    "    print('X shape: ', X.shape)\n",
    "    print('Y shape: ', Y.shape)\n",
    "    np.savetxt('features.txt', X,\n",
    "           fmt='%.6f',           # Format (2 decimal places)\n",
    "           delimiter=',')\n",
    "    return X, Y\n",
    "\n",
    "X_train, Y_train = extract_features(audio_ids=ids_train, audio_features_file=nn_features, lyrics_features=panda_merge_lyrics_features, truth_pred=Y_pred)"
   ],
   "id": "aef100e0ebe3528d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128,)\n",
      "run stats\n",
      "count:  258\n",
      "missing:  1293\n",
      "X shape:  (259, 128)\n",
      "Y shape:  (259, 2)\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "NN modelling",
   "id": "3e7bf3038be61d5d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "870d971d0c0a178d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
